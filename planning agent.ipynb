{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T09:59:02.868561800Z",
     "start_time": "2026-02-26T09:59:02.796999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(\n",
    "    \"postgresql+psycopg2://postgres:2004@localhost:5432/company_db\"\n",
    ")"
   ],
   "id": "8cde48218ef8c957",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T09:59:04.336372700Z",
     "start_time": "2026-02-26T09:59:02.901911900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# ==============================\n",
    "# SET YOUR OPENROUTER KEY HERE\n",
    "# ==============================\n",
    "\n",
    "os.environ[\"OPENROUTER_API_KEY\"] = \"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\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    ")\n",
    "\n",
    "print(\"âœ… OpenRouter client ready\")"
   ],
   "id": "c2d2588bc96cc818",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenRouter client ready\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T09:59:04.424581900Z",
     "start_time": "2026-02-26T09:59:04.379991600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_schema_metadata():\n",
    "    query = \"\"\"\n",
    "    SELECT table_name, column_name, data_type\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = 'public'\n",
    "    ORDER BY table_name, ordinal_position;\n",
    "    \"\"\"\n",
    "\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(query))\n",
    "        return [dict(row._mapping) for row in result]"
   ],
   "id": "4b2b914c8483e19d",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T09:59:04.449390800Z",
     "start_time": "2026-02-26T09:59:04.431639400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from decimal import Decimal\n",
    "from datetime import date, datetime\n",
    "\n",
    "def serialize_value(value):\n",
    "    if isinstance(value, Decimal):\n",
    "        return float(value)\n",
    "    if isinstance(value, (date, datetime)):\n",
    "        return value.isoformat()\n",
    "    return value\n",
    "\n",
    "\n",
    "def query_postgres(sql_query: str):\n",
    "\n",
    "    if not sql_query.strip().lower().startswith(\"select\"):\n",
    "        return {\"error\": \"Only SELECT queries allowed\"}\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(sql_query))\n",
    "            rows = []\n",
    "\n",
    "            for row in result:\n",
    "                row_dict = {}\n",
    "                for key, value in row._mapping.items():\n",
    "                    row_dict[key] = serialize_value(value)\n",
    "                rows.append(row_dict)\n",
    "\n",
    "            return rows\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ],
   "id": "18f3fa8f43636522",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T09:59:04.478402200Z",
     "start_time": "2026-02-26T09:59:04.460688900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_schema_metadata\",\n",
    "            \"description\": \"Read database schema using SQL metadata tables\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"query_postgres\",\n",
    "            \"description\": \"Execute read-only SQL query\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"sql_query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"SQL SELECT query\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"sql_query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ],
   "id": "ae28963dc5ff1ed7",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T09:59:04.520532Z",
     "start_time": "2026-02-26T09:59:04.481854800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def execute_tool(name, arguments):\n",
    "\n",
    "    if name == \"get_schema_metadata\":\n",
    "        return get_schema_metadata()\n",
    "\n",
    "    elif name == \"query_postgres\":\n",
    "        return query_postgres(arguments[\"sql_query\"])\n",
    "\n",
    "    else:\n",
    "        return {\"error\": \"Unknown tool\"}"
   ],
   "id": "d0c2efc98cd33b26",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T09:59:04.549639100Z",
     "start_time": "2026-02-26T09:59:04.525004900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an autonomous PostgreSQL analysis agent.\n",
    "\n",
    "STRICT RULES:\n",
    "1. You MUST first call get_schema_metadata to understand the database structure.\n",
    "2. Never assume table or column names.\n",
    "3. After seeing schema, generate a SELECT query.\n",
    "4. Only SELECT queries allowed.\n",
    "5. Never use INSERT, UPDATE, DELETE, DROP.\n",
    "6. After receiving SQL results, explain clearly.\n",
    "\n",
    "You must reason step by step.\n",
    "\"\"\""
   ],
   "id": "a43665c74698f507",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T09:59:04.690574800Z",
     "start_time": "2026-02-26T09:59:04.564361600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def autonomous_agent(user_question, max_iterations=6):\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_question}\n",
    "    ]\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"openai/gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        message = response.choices[0].message\n",
    "\n",
    "        # Tool call\n",
    "        if message.tool_calls:\n",
    "\n",
    "            messages.append(message)\n",
    "\n",
    "            for tool_call in message.tool_calls:\n",
    "                tool_name = tool_call.function.name\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                print(f\"\\nðŸ”§ Iteration {i+1}: Calling {tool_name}\")\n",
    "\n",
    "                result = execute_tool(tool_name, arguments)\n",
    "\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "\n",
    "        else:\n",
    "            return message.content\n",
    "\n",
    "    return \"âš  Max iterations reached.\""
   ],
   "id": "8632317d89d506c0",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T09:59:12.021951600Z",
     "start_time": "2026-02-26T09:59:04.752973900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"Which department has the highest total salary expense?\"\n",
    "\n",
    "result = autonomous_agent(question)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"FINAL ANSWER\")\n",
    "print(\"==============================\\n\")\n",
    "print(result)"
   ],
   "id": "981056524a4e7046",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”§ Iteration 1: Calling get_schema_metadata\n",
      "\n",
      "ðŸ”§ Iteration 2: Calling query_postgres\n",
      "\n",
      "ðŸ”§ Iteration 3: Calling query_postgres\n",
      "\n",
      "==============================\n",
      "FINAL ANSWER\n",
      "==============================\n",
      "\n",
      "The department with the highest total salary expense is **Research & Development**, with a total salary expense of **$6,036,284**. \n",
      "\n",
      "This was determined by summing the monthly income of all employees grouped by their respective departments and identifying the department with the highest total.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2355799046197eb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T10:06:17.264423700Z",
     "start_time": "2026-02-26T10:06:17.235204800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "from decimal import Decimal\n",
    "from datetime import date, datetime\n",
    "from openai import OpenAI\n",
    "from sqlalchemy import create_engine, text\n"
   ],
   "id": "94d7a8f41c2fd5a7",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T10:18:57.498383800Z",
     "start_time": "2026-02-26T10:18:57.432448900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_schema_metadata():\n",
    "    query = \"\"\"\n",
    "    SELECT table_name, column_name, data_type\n",
    "    FROM information_schema.columns\n",
    "    WHERE table_schema = 'public'\n",
    "    ORDER BY table_name, ordinal_position;\n",
    "    \"\"\"\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(text(query))\n",
    "        return [dict(row._mapping) for row in result]"
   ],
   "id": "341d8ffa38ff61cf",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T10:19:09.751257Z",
     "start_time": "2026-02-26T10:19:09.698390100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_query_plan(user_question, schema_metadata):\n",
    "\n",
    "    schema_text = json.dumps(schema_metadata, indent=2)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a PostgreSQL structured query planner.\n",
    "\n",
    "Schema (JSON):\n",
    "{schema_text}\n",
    "\n",
    "User question:\n",
    "{user_question}\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "\n",
    "{{\n",
    "  \"table\": \"\",\n",
    "  \"select_columns\": [],\n",
    "  \"aggregations\": [\n",
    "      {{\n",
    "        \"function\": \"\",\n",
    "        \"column\": \"\",\n",
    "        \"alias\": \"\"\n",
    "      }}\n",
    "  ],\n",
    "  \"filters\": [\n",
    "      {{\n",
    "        \"column\": \"\",\n",
    "        \"operator\": \"=\",\n",
    "        \"value\": \"\"\n",
    "      }}\n",
    "  ],\n",
    "  \"group_by\": [],\n",
    "  \"order_by\": {{\n",
    "      \"type\": \"column|aggregation\",\n",
    "      \"value\": \"\"\n",
    "  }},\n",
    "  \"order_direction\": \"ASC|DESC\",\n",
    "  \"limit\": 10,\n",
    "  \"explanation\": \"\"\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- Use EXACT table and column names.\n",
    "- Do NOT write SQL.\n",
    "- Do NOT invent columns.\n",
    "- If no aggregation needed, return empty list.\n",
    "- If no filters, return empty list.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ],
   "id": "dc692894ed33038e",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T10:19:21.584042600Z",
     "start_time": "2026-02-26T10:19:21.540129300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validate_plan(plan_json, schema_metadata):\n",
    "\n",
    "    try:\n",
    "        plan = json.loads(plan_json)\n",
    "    except:\n",
    "        return False, \"Invalid JSON\"\n",
    "\n",
    "    tables = {}\n",
    "    for row in schema_metadata:\n",
    "        tables.setdefault(row[\"table_name\"], []).append(row[\"column_name\"])\n",
    "\n",
    "    table = plan.get(\"table\")\n",
    "    if table not in tables:\n",
    "        return False, f\"Invalid table: {table}\"\n",
    "\n",
    "    valid_columns = set(tables[table])\n",
    "\n",
    "    # Validate select columns\n",
    "    for col in plan.get(\"select_columns\", []):\n",
    "        if col not in valid_columns:\n",
    "            return False, f\"Invalid select column: {col}\"\n",
    "\n",
    "    # Validate aggregations\n",
    "    for agg in plan.get(\"aggregations\", []):\n",
    "        if agg[\"column\"] not in valid_columns:\n",
    "            return False, f\"Invalid aggregation column: {agg['column']}\"\n",
    "\n",
    "    # Validate filters\n",
    "    for f in plan.get(\"filters\", []):\n",
    "        if f[\"column\"] not in valid_columns:\n",
    "            return False, f\"Invalid filter column: {f['column']}\"\n",
    "\n",
    "    return True, plan"
   ],
   "id": "64bfa6a240d270e1",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T10:19:32.937800Z",
     "start_time": "2026-02-26T10:19:32.906536400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_sql_from_plan(plan):\n",
    "\n",
    "    table = f'\"{plan[\"table\"]}\"'\n",
    "\n",
    "    select_parts = []\n",
    "\n",
    "    # Add normal columns\n",
    "    for col in plan.get(\"select_columns\", []):\n",
    "        select_parts.append(f'\"{col}\"')\n",
    "\n",
    "    # Add aggregations\n",
    "    for agg in plan.get(\"aggregations\", []):\n",
    "        func = agg[\"function\"].upper()\n",
    "        column = agg[\"column\"]\n",
    "        alias = agg[\"alias\"]\n",
    "\n",
    "        expr = f'{func}(\"{column}\")'\n",
    "        if alias:\n",
    "            expr += f' AS \"{alias}\"'\n",
    "\n",
    "        select_parts.append(expr)\n",
    "\n",
    "    select_clause = \", \".join(select_parts)\n",
    "\n",
    "    sql = f\"SELECT {select_clause} FROM {table}\"\n",
    "\n",
    "    # WHERE\n",
    "    if plan[\"filters\"]:\n",
    "        clauses = []\n",
    "        for f in plan[\"filters\"]:\n",
    "            col = f'\"{f[\"column\"]}\"'\n",
    "            val = f[\"value\"]\n",
    "            if isinstance(val, str):\n",
    "                val = f\"'{val}'\"\n",
    "            clauses.append(f\"{col} {f['operator']} {val}\")\n",
    "        sql += \" WHERE \" + \" AND \".join(clauses)\n",
    "\n",
    "    # GROUP BY\n",
    "    if plan[\"group_by\"]:\n",
    "        cols = [f'\"{c}\"' for c in plan[\"group_by\"]]\n",
    "        sql += \" GROUP BY \" + \", \".join(cols)\n",
    "\n",
    "    # ORDER BY\n",
    "    if plan[\"order_by\"][\"value\"]:\n",
    "        if plan[\"order_by\"][\"type\"] == \"column\":\n",
    "            col = f'\"{plan[\"order_by\"][\"value\"]}\"'\n",
    "            sql += f\" ORDER BY {col} {plan['order_direction']}\"\n",
    "        elif plan[\"order_by\"][\"type\"] == \"aggregation\":\n",
    "            for agg in plan[\"aggregations\"]:\n",
    "                if agg[\"alias\"] == plan[\"order_by\"][\"value\"]:\n",
    "                    func = agg[\"function\"].upper()\n",
    "                    column = agg[\"column\"]\n",
    "                    sql += f' ORDER BY {func}(\"{column}\") {plan[\"order_direction\"]}'\n",
    "                    break\n",
    "\n",
    "    # LIMIT\n",
    "    if plan[\"limit\"]:\n",
    "        sql += f\" LIMIT {int(plan['limit'])}\"\n",
    "\n",
    "    return sql"
   ],
   "id": "9b6094ad6bebd607",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T10:19:44.629618300Z",
     "start_time": "2026-02-26T10:19:44.577119600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def serialize_value(value):\n",
    "    if isinstance(value, Decimal):\n",
    "        return float(value)\n",
    "    if isinstance(value, (date, datetime)):\n",
    "        return value.isoformat()\n",
    "    return value\n",
    "\n",
    "\n",
    "def execute_sql(sql_query):\n",
    "\n",
    "    if not sql_query.strip().lower().startswith(\"select\"):\n",
    "        return {\"error\": \"Only SELECT allowed\"}\n",
    "\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(sql_query))\n",
    "            rows = []\n",
    "            for row in result:\n",
    "                row_dict = {\n",
    "                    key: serialize_value(val)\n",
    "                    for key, val in row._mapping.items()\n",
    "                }\n",
    "                rows.append(row_dict)\n",
    "            return rows\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}"
   ],
   "id": "a6aaa313777612fa",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T10:19:54.546693600Z",
     "start_time": "2026-02-26T10:19:54.502607100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reflect(user_question, sql_result):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "User Question:\n",
    "{user_question}\n",
    "\n",
    "SQL Result:\n",
    "{sql_result}\n",
    "\n",
    "Explain clearly and concisely.\n",
    "If result is empty, explain why.\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ],
   "id": "5b653bdeb58849c6",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T10:20:06.208498900Z",
     "start_time": "2026-02-26T10:20:06.182886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def structured_sql_agent(user_question):\n",
    "\n",
    "    # Step 1: Read schema\n",
    "    schema_metadata = get_schema_metadata()\n",
    "\n",
    "    # Step 2: Generate structured plan\n",
    "    plan_json = generate_query_plan(user_question, schema_metadata)\n",
    "    print(\"Generated Plan:\\n\", plan_json)\n",
    "\n",
    "    # Step 3: Validate\n",
    "    valid, plan_or_error = validate_plan(plan_json, schema_metadata)\n",
    "    if not valid:\n",
    "        return f\"Validation failed: {plan_or_error}\"\n",
    "\n",
    "    plan = plan_or_error\n",
    "\n",
    "    # Step 4: Build SQL\n",
    "    sql = build_sql_from_plan(plan)\n",
    "    print(\"\\nBuilt SQL:\\n\", sql)\n",
    "\n",
    "    # Step 5: Execute\n",
    "    result = execute_sql(sql)\n",
    "\n",
    "    # Step 6: Reflect\n",
    "    return reflect(user_question, result)"
   ],
   "id": "20471194e1ec5ec8",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T10:20:20.863940800Z",
     "start_time": "2026-02-26T10:20:13.109972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"Which department has the highest total salary expense?\"\n",
    "\n",
    "result = structured_sql_agent(question)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"FINAL ANSWER\")\n",
    "print(\"==============================\\n\")\n",
    "print(result)"
   ],
   "id": "7deca2ff3ad89dcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Plan:\n",
      " {\n",
      "  \"table\": \"employees\",\n",
      "  \"select_columns\": [\n",
      "    \"Department\"\n",
      "  ],\n",
      "  \"aggregations\": [\n",
      "    {\n",
      "      \"function\": \"SUM\",\n",
      "      \"column\": \"MonthlyIncome\",\n",
      "      \"alias\": \"TotalSalaryExpense\"\n",
      "    }\n",
      "  ],\n",
      "  \"filters\": [],\n",
      "  \"group_by\": [\n",
      "    \"Department\"\n",
      "  ],\n",
      "  \"order_by\": {\n",
      "    \"type\": \"aggregation\",\n",
      "    \"value\": \"TotalSalaryExpense\"\n",
      "  },\n",
      "  \"order_direction\": \"DESC\",\n",
      "  \"limit\": 1,\n",
      "  \"explanation\": \"This query calculates the total salary expense for each department by summing the MonthlyIncome and orders the results in descending order to find the department with the highest total salary expense.\"\n",
      "}\n",
      "\n",
      "Built SQL:\n",
      " SELECT \"Department\", SUM(\"MonthlyIncome\") AS \"TotalSalaryExpense\" FROM \"employees\" GROUP BY \"Department\" ORDER BY SUM(\"MonthlyIncome\") DESC LIMIT 1\n",
      "\n",
      "==============================\n",
      "FINAL ANSWER\n",
      "==============================\n",
      "\n",
      "The SQL result indicates that the department with the highest total salary expense is \"Research & Development,\" with a total salary expense of $6,036,284. This means that among all departments in the dataset, Research & Development has the largest financial outlay for employee salaries.\n",
      "\n",
      "If the result were empty, it could indicate several possibilities, such as:\n",
      "1. There are no departments in the dataset.\n",
      "2. There are departments, but none have recorded salary expenses.\n",
      "3. The query used to retrieve the data may have been incorrect or did not match any records.\n",
      "\n",
      "In this case, since we do have a result, it confirms that the Research & Development department has the highest salary expense.\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8f67e41d820191a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
